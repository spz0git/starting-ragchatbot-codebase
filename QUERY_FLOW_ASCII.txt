═══════════════════════════════════════════════════════════════════════════════════════════
                    RAG CHATBOT - QUERY FLOW DIAGRAM
═══════════════════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 1: FRONTEND - USER INPUT                                                           │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────┐
    │   User Browser   │
    │   index.html     │
    │  (Chat UI)       │
    └────────┬─────────┘
             │
             │ Type query: "What is MCP?"
             ↓
    ┌──────────────────────────────────────┐
    │  script.js - sendMessage()           │
    │  • Get query from input              │
    │  • Add user message to chat          │
    │  • Show loading indicator            │
    └────────┬───────────────────────────┘
             │
             │ POST /api/query
             │ {
             │   "query": "What is MCP?",
             │   "session_id": null
             │ }
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 2: BACKEND - API ENDPOINT (FastAPI)                                                │
└─────────────────────────────────────────────────────────────────────────────────────────┘

             ┌──────────────────────────────────────┐
             │  FastAPI: app.py                     │
             │  @app.post("/api/query")             │
             └────────┬─────────────────────────────┘
                      │
                      │ 1. Create session (if needed)
                      │    session_id = "session_1"
                      │
                      ↓
             ┌────────────────────────────────────────┐
             │ RAG System Initialization             │
             │ • DocumentProcessor                  │
             │ • VectorStore (ChromaDB)             │
             │ • AIGenerator (Claude)               │
             │ • SessionManager                     │
             └────────┬────────────────────────────┘
                      │
                      │ 2. Call: rag_system.query()
                      ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 3: RAG SYSTEM - ORCHESTRATION (rag_system.py)                                     │
└─────────────────────────────────────────────────────────────────────────────────────────┘

             ┌──────────────────────────────────┐
             │  RAG System                      │
             └────────┬─────────────────────────┘
                      │
                      ├─→ SessionManager
                      │   Get conversation history
                      │   (if session_id exists)
                      │
                      └─→ AIGenerator
                          • query = "Answer: What is MCP?"
                          • history = previous messages
                          • tools = [search_course_content]
                          • Calls: generate_response()
                      ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 4: AI GENERATOR - CLAUDE API CALL (ai_generator.py)                                │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────────────────────────────────────┐
    │  AIGenerator: generate_response()                │
    │                                                  │
    │  Build API Parameters:                          │
    │  • model: "claude-3-5-sonnet-20241022"         │
    │  • system_prompt: (with conversation history)   │
    │  • messages: [{"role": "user", "content": ...}] │
    │  • tools: [search_course_content definition]   │
    │  • temperature: 0 (deterministic)              │
    │  • max_tokens: 800                             │
    └────────┬────────────────────────────────────────┘
             │
             │ Call: anthropic.messages.create()
             │
             ↓
    ┌──────────────────────────────────────┐
    │  Claude API (Anthropic)              │
    │                                      │
    │  Receives:                          │
    │  • Query about MCP                  │
    │  • Tool definition for search       │
    │  • Conversation history             │
    └────────┬─────────────────────────────┘
             │
             │ Claude analyzes query:
             │ "This is a course-specific question"
             │ "I should use the search tool"
             │
             ↓
    ┌────────────────────────────────────────┐
    │  Claude Response (tool_use)            │
    │  {                                     │
    │    "type": "tool_use",                │
    │    "name": "search_course_content",   │
    │    "input": {                         │
    │      "query": "MCP model context"     │
    │    }                                  │
    │  }                                    │
    └────────┬────────────────────────────────┘
             │
             ├─→ response.stop_reason == "tool_use"
             │
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 5: TOOL EXECUTION (search_tools.py)                                                │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────────────────────────────┐
    │  ToolManager: execute_tool()             │
    │  tool_name = "search_course_content"     │
    └────────┬───────────────────────────────┘
             │
             ↓
    ┌──────────────────────────────────────────┐
    │  CourseSearchTool: execute()             │
    │  • query: "MCP model context protocol"   │
    │  • course_name: None (optional)          │
    │  • lesson_number: None (optional)        │
    └────────┬───────────────────────────────┘
             │
             │ Call: vector_store.search()
             │
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 6: VECTOR STORE - SEMANTIC SEARCH (vector_store.py)                               │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────┐
    │  VectorStore: search()                 │
    │                                        │
    │  1. Resolve course name (if provided)  │
    │     → Semantic search in course_catalog│
    │                                        │
    │  2. Build filter                       │
    │     → {"course_title": "...",          │
    │        "lesson_number": ...}           │
    │                                        │
    │  3. Search course content              │
    │     → chromadb.query()                 │
    └────────┬─────────────────────────────┘
             │
             ↓
    ┌────────────────────────────────────────┐
    │  ChromaDB: Vector Database             │
    │                                        │
    │  1. SentenceTransformer encoder        │
    │     Encode query: "MCP..." → vector   │
    │                                        │
    │  2. Semantic similarity search         │
    │     Find top 5 nearest chunks          │
    │                                        │
    │  3. Return results with metadata:      │
    │     • documents: [chunk1, chunk2...]  │
    │     • metadata: [                      │
    │         {course_title: "Intro to MCP", │
    │          lesson_number: 1,             │
    │          chunk_index: 0},              │
    │         ...                            │
    │       ]                                │
    │     • distances: [0.23, 0.45, ...]    │
    └────────┬─────────────────────────────┘
             │
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 7: FORMAT RESULTS (search_tools.py)                                                │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────┐
    │  CourseSearchTool: _format_results()   │
    │                                        │
    │  For each result:                      │
    │  [Introduction to MCP - Lesson 1]      │
    │  MCP stands for Model Context...       │
    │                                        │
    │  [Introduction to MCP - Lesson 2]      │
    │  The protocol enables AI...            │
    │                                        │
    │  Store sources for UI:                 │
    │  ["Intro to MCP - Lesson 1",          │
    │   "Intro to MCP - Lesson 2"]          │
    └────────┬─────────────────────────────┘
             │
             │ Tool result string
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 8: CLAUDE GENERATES FINAL ANSWER (ai_generator.py)                                │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────┐
    │  AIGenerator: _handle_tool_execution() │
    │                                        │
    │  1. Append AI's tool use response     │
    │  2. Execute tool & get results        │
    │  3. Send results back to Claude       │
    │  4. Claude generates final answer     │
    └────────┬─────────────────────────────┘
             │
             │ Claude's Final Response:
             │ "MCP (Model Context Protocol) is..."
             │
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 9: RETURN RESPONSE (rag_system.py → app.py)                                       │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────┐
    │  RAG System                            │
    │                                        │
    │  1. Get response from AI Generator    │
    │  2. Get sources from ToolManager      │
    │  3. Update SessionManager with        │
    │     user query + assistant answer    │
    │                                        │
    │  Return: (response, sources)          │
    └────────┬─────────────────────────────┘
             │
             ↓
    ┌────────────────────────────────────────┐
    │  FastAPI: query_documents()            │
    │                                        │
    │  Return QueryResponse:                 │
    │  {                                     │
    │    "answer": "MCP is...",             │
    │    "sources": [                       │
    │      "Intro to MCP - Lesson 1",       │
    │      "Intro to MCP - Lesson 2"        │
    │    ],                                  │
    │    "session_id": "session_1"          │
    │  }                                     │
    └────────┬─────────────────────────────┘
             │
             │ JSON Response
             ↓


┌─────────────────────────────────────────────────────────────────────────────────────────┐
│ STEP 10: FRONTEND DISPLAYS RESULT (script.js)                                          │
└─────────────────────────────────────────────────────────────────────────────────────────┘

    ┌────────────────────────────────────────┐
    │  Frontend: sendMessage()               │
    │                                        │
    │  1. Parse JSON response                │
    │  2. Update session_id (first time)    │
    │  3. Remove loading indicator          │
    │  4. Call addMessage()                  │
    │  5. Render markdown answer            │
    │  6. Add collapsible sources section    │
    │                                        │
    │  Display:                              │
    │  ┌─────────────────────────────┐     │
    │  │ MCP (Model Context Protocol)│     │
    │  │ is a standardized protocol  │     │
    │  │ that enables...             │     │
    │  │                             │     │
    │  │ ▼ Sources                   │     │
    │  │  • Intro to MCP - Lesson 1  │     │
    │  │  • Intro to MCP - Lesson 2  │     │
    │  └─────────────────────────────┘     │
    └────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════
                            KEY COMPONENTS & FILES
═══════════════════════════════════════════════════════════════════════════════════════════

FRONTEND:
  • index.html      - Chat UI with message display and input
  • script.js       - Event handlers, API calls, message rendering
  • style.css       - Styling

BACKEND:
  • app.py          - FastAPI app, REST endpoints
  • rag_system.py   - RAG orchestrator, combines all components
  • ai_generator.py - Claude API integration with tool support
  • search_tools.py - Tool definitions and execution
  • vector_store.py - ChromaDB wrapper for semantic search
  • session_manager.py - Conversation history management
  • document_processor.py - Document loading and chunking
  • config.py       - Configuration settings
  • models.py       - Data models (Course, Lesson, CourseChunk)

VECTOR DATABASE:
  • ChromaDB        - Persistent vector store (chroma_data/ directory)
  • SentenceTransformer - Embedding model for semantic search

EXTERNAL APIs:
  • Anthropic Claude API - AI response generation with tools


═══════════════════════════════════════════════════════════════════════════════════════════
                            TIMING & LATENCY
═══════════════════════════════════════════════════════════════════════════════════════════

Frontend Input         ~0ms    (immediate)
FastAPI Processing    ~10ms
RAG Orchestration     ~5ms
Claude API Call       ~2000ms  (primary latency)
├─ Claude decides tool usage    ~500ms
├─ Tool execution               ~500ms
└─ Final response generation    ~1000ms
Vector Search         ~200ms
Format Response       ~5ms
Frontend Render       ~50ms
                      ──────
Total Time            ~2-3s    (typical)


═══════════════════════════════════════════════════════════════════════════════════════════
